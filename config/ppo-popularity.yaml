agent:
trainer:
  trainer_cls: 'PPO'
  policy: "MlpPolicy"
  learning_rate: 1e-3
  learning_rate_schedule: True
  n_steps: 1024
  batch_size: 8192 # env_size * n_steps
  n_epochs: 16
  policy_kwargs: 
    net_arch: 
      pi: [256, 128, 64]
      vf: [256, 128, 64]
  gamma: 0.95
  verbose: 0 
  tensorboard_log: "./tmp/tensorboard/"
  total_timesteps: 1e7
  progress_bar: True
  device: "cpu"
  # 3. PPO特有参数
  clip_range: 0.3        # 限制策略更新步长
  ent_coef: 0.01        # 提高探索度
env:
  id: "LayerEdgeDynamicEnv-v0"
  storage_type: "PopularityStorage"
  prefix: "popularity"
